#include "application.h"
#include "assets/lang_config.h"
#include "audio_codec.h"
#include "board.h"
#include "display.h"
#include "mqtt_protocol.h"
#include "system_info.h"
#include "touch_handler.h"
#include "websocket_protocol.h"

namespace {
constexpr const char *kTouchMessage = "ï¼ˆç”¨æˆ·è½»è½»æ‘¸äº†æ‘¸ä½ çš„å¤´ï¼‰";
constexpr int64_t kTouchStartAckTimeoutUs = 700'000; // 700ms
} // namespace

#include "assets.h"
#include "core/event_bus.h"
#include "learning/adaptive_behavior.h"
#include "learning/decision_engine.h"
#include "learning/emotional_memory.h"
#include "learning/user_profile.h"
#include "mcp_server.h"
#include "pet_system.h"
#include "settings.h"

#include <arpa/inet.h>
#include <cJSON.h>
#include <cstring>
#include <driver/gpio.h>
#include <esp_log.h>
#include <esp_timer.h>
#include <font_awesome.h>

#define TAG "Application"

static const char *const STATE_STRINGS[] = {
    "unknown",    "starting",      "configuring", "idle",
    "connecting", "listening",     "speaking",    "upgrading",
    "activating", "audio_testing", "fatal_error", "invalid_state"};

// å£°æ˜å¤–éƒ¨ Otto åŠ¨ä½œå‡½æ•°
extern void OttoSwing(int steps, int speed, int amount);
extern void OttoJump(int steps, int speed);

Application::Application() {
  event_group_ = xEventGroupCreate();

#if CONFIG_USE_DEVICE_AEC && CONFIG_USE_SERVER_AEC
#error                                                                         \
    "CONFIG_USE_DEVICE_AEC and CONFIG_USE_SERVER_AEC cannot be enabled at the same time"
#elif CONFIG_USE_DEVICE_AEC
  aec_mode_ = kAecOnDeviceSide;
#elif CONFIG_USE_SERVER_AEC
  aec_mode_ = kAecOnServerSide;
#else
  aec_mode_ = kAecOff;
#endif

  esp_timer_create_args_t clock_timer_args = {
      .callback =
          [](void *arg) {
            Application *app = (Application *)arg;
            xEventGroupSetBits(app->event_group_, MAIN_EVENT_CLOCK_TICK);
          },
      .arg = this,
      .dispatch_method = ESP_TIMER_TASK,
      .name = "clock_timer",
      .skip_unhandled_events = true};
  esp_timer_create(&clock_timer_args, &clock_timer_handle_);
}

Application::~Application() {
  if (clock_timer_handle_ != nullptr) {
    esp_timer_stop(clock_timer_handle_);
    esp_timer_delete(clock_timer_handle_);
  }
  vEventGroupDelete(event_group_);
}

void Application::CheckAssetsVersion() {
  auto &board = Board::GetInstance();
  auto display = board.GetDisplay();
  auto &assets = Assets::GetInstance();

  if (!assets.partition_valid()) {
    ESP_LOGW(TAG, "Assets partition is disabled for board %s", BOARD_NAME);
    return;
  }

  Settings settings("assets", true);
  // Check if there is a new assets need to be downloaded
  std::string download_url = settings.GetString("download_url");

  if (!download_url.empty()) {
    settings.EraseKey("download_url");

    char message[256];
    snprintf(message, sizeof(message), Lang::Strings::FOUND_NEW_ASSETS,
             download_url.c_str());
    Alert(Lang::Strings::LOADING_ASSETS, message, "cloud_arrow_down",
          Lang::Sounds::OGG_UPGRADE);

    // Wait for the audio service to be idle for 3 seconds
    vTaskDelay(pdMS_TO_TICKS(3000));
    SetDeviceState(kDeviceStateUpgrading);
    board.SetPowerSaveMode(false);
    display->SetChatMessage("system", Lang::Strings::PLEASE_WAIT);

    bool success = assets.Download(
        download_url, [display](int progress, size_t speed) -> void {
          std::thread([display, progress, speed]() {
            char buffer[32];
            snprintf(buffer, sizeof(buffer), "%d%% %uKB/s", progress,
                     speed / 1024);
            display->SetChatMessage("system", buffer);
          }).detach();
        });

    board.SetPowerSaveMode(true);
    vTaskDelay(pdMS_TO_TICKS(1000));

    if (!success) {
      Alert(Lang::Strings::ERROR, Lang::Strings::DOWNLOAD_ASSETS_FAILED,
            "circle_xmark", Lang::Sounds::OGG_EXCLAMATION);
      vTaskDelay(pdMS_TO_TICKS(2000));
      return;
    }
  }

  // Apply assets
  assets.Apply();
  display->SetChatMessage("system", "");
  display->SetEmotion("microchip_ai");
}

void Application::CheckNewVersion(Ota &ota) {
  const int MAX_RETRY = 10;
  int retry_count = 0;
  int retry_delay = 10; // åˆå§‹é‡è¯•å»¶è¿Ÿä¸º10ç§’

  auto &board = Board::GetInstance();
  while (true) {
    SetDeviceState(kDeviceStateActivating);
    auto display = board.GetDisplay();
    display->SetStatus(Lang::Strings::CHECKING_NEW_VERSION);

    if (!ota.CheckVersion()) {
      retry_count++;
      if (retry_count >= MAX_RETRY) {
        ESP_LOGE(TAG, "Too many retries, exit version check");
        return;
      }

      char buffer[256];
      snprintf(buffer, sizeof(buffer), Lang::Strings::CHECK_NEW_VERSION_FAILED,
               retry_delay, ota.GetCheckVersionUrl().c_str());
      Alert(Lang::Strings::ERROR, buffer, "cloud_slash",
            Lang::Sounds::OGG_EXCLAMATION);

      ESP_LOGW(TAG, "Check new version failed, retry in %d seconds (%d/%d)",
               retry_delay, retry_count, MAX_RETRY);
      for (int i = 0; i < retry_delay; i++) {
        vTaskDelay(pdMS_TO_TICKS(1000));
        if (device_state_ == kDeviceStateIdle) {
          break;
        }
      }
      retry_delay *= 2; // æ¯æ¬¡é‡è¯•åå»¶è¿Ÿæ—¶é—´ç¿»å€
      continue;
    }
    retry_count = 0;
    retry_delay = 10; // é‡ç½®é‡è¯•å»¶è¿Ÿæ—¶é—´

    if (ota.HasNewVersion()) {
      if (UpgradeFirmware(ota)) {
        return; // This line will never be reached after reboot
      }
      // If upgrade failed, continue to normal operation (don't break, just fall
      // through)
    }

    // No new version, mark the current version as valid
    ota.MarkCurrentVersionValid();
    if (!ota.HasActivationCode() && !ota.HasActivationChallenge()) {
      xEventGroupSetBits(event_group_, MAIN_EVENT_CHECK_NEW_VERSION_DONE);
      // Exit the loop if done checking new version
      break;
    }

    display->SetStatus(Lang::Strings::ACTIVATION);
    // Activation code is shown to the user and waiting for the user to input
    if (ota.HasActivationCode()) {
      ShowActivationCode(ota.GetActivationCode(), ota.GetActivationMessage());
    }

    // This will block the loop until the activation is done or timeout
    for (int i = 0; i < 10; ++i) {
      ESP_LOGI(TAG, "Activating... %d/%d", i + 1, 10);
      esp_err_t err = ota.Activate();
      if (err == ESP_OK) {
        xEventGroupSetBits(event_group_, MAIN_EVENT_CHECK_NEW_VERSION_DONE);
        break;
      } else if (err == ESP_ERR_TIMEOUT) {
        vTaskDelay(pdMS_TO_TICKS(3000));
      } else {
        vTaskDelay(pdMS_TO_TICKS(10000));
      }
      if (device_state_ == kDeviceStateIdle) {
        break;
      }
    }
  }
}

void Application::ShowActivationCode(const std::string &code,
                                     const std::string &message) {
  struct digit_sound {
    char digit;
    const std::string_view &sound;
  };
  static const std::array<digit_sound, 10> digit_sounds{
      {digit_sound{'0', Lang::Sounds::OGG_0},
       digit_sound{'1', Lang::Sounds::OGG_1},
       digit_sound{'2', Lang::Sounds::OGG_2},
       digit_sound{'3', Lang::Sounds::OGG_3},
       digit_sound{'4', Lang::Sounds::OGG_4},
       digit_sound{'5', Lang::Sounds::OGG_5},
       digit_sound{'6', Lang::Sounds::OGG_6},
       digit_sound{'7', Lang::Sounds::OGG_7},
       digit_sound{'8', Lang::Sounds::OGG_8},
       digit_sound{'9', Lang::Sounds::OGG_9}}};

  // This sentence uses 9KB of SRAM, so we need to wait for it to finish
  Alert(Lang::Strings::ACTIVATION, message.c_str(), "link",
        Lang::Sounds::OGG_ACTIVATION);

  for (const auto &digit : code) {
    auto it = std::find_if(
        digit_sounds.begin(), digit_sounds.end(),
        [digit](const digit_sound &ds) { return ds.digit == digit; });
    if (it != digit_sounds.end()) {
      audio_service_.PlaySound(it->sound);
    }
  }
}

void Application::Alert(const char *status, const char *message,
                        const char *emotion, const std::string_view &sound) {
  ESP_LOGW(TAG, "Alert [%s] %s: %s", emotion, status, message);
  auto display = Board::GetInstance().GetDisplay();
  display->SetStatus(status);
  display->SetEmotion(emotion);
  display->SetChatMessage("system", message);
  if (!sound.empty()) {
    audio_service_.PlaySound(sound);
  }
}

void Application::DismissAlert() {
  if (device_state_ == kDeviceStateIdle) {
    auto display = Board::GetInstance().GetDisplay();
    display->SetStatus(Lang::Strings::STANDBY);
    display->SetEmotion("neutral");
    display->SetChatMessage("system", "");
  }
}

void Application::ToggleChatState() {
  if (device_state_ == kDeviceStateActivating) {
    SetDeviceState(kDeviceStateIdle);
    return;
  } else if (device_state_ == kDeviceStateWifiConfiguring) {
    audio_service_.EnableAudioTesting(true);
    SetDeviceState(kDeviceStateAudioTesting);
    return;
  } else if (device_state_ == kDeviceStateAudioTesting) {
    audio_service_.EnableAudioTesting(false);
    SetDeviceState(kDeviceStateWifiConfiguring);
    return;
  }

  if (!protocol_) {
    ESP_LOGE(TAG, "Protocol not initialized");
    return;
  }

  if (device_state_ == kDeviceStateIdle) {
    Schedule([this]() {
      if (!protocol_->IsAudioChannelOpened()) {
        SetDeviceState(kDeviceStateConnecting);
        if (!protocol_->OpenAudioChannel()) {
          return;
        }
      }

      SetListeningMode(aec_mode_ == kAecOff ? kListeningModeAutoStop
                                            : kListeningModeRealtime);
    });
  } else if (device_state_ == kDeviceStateSpeaking) {
    Schedule([this]() { AbortSpeaking(kAbortReasonNone); });
  } else if (device_state_ == kDeviceStateListening) {
    Schedule([this]() { protocol_->CloseAudioChannel(); });
  }
}

void Application::StartListening() {
  if (device_state_ == kDeviceStateActivating) {
    SetDeviceState(kDeviceStateIdle);
    return;
  } else if (device_state_ == kDeviceStateWifiConfiguring) {
    audio_service_.EnableAudioTesting(true);
    SetDeviceState(kDeviceStateAudioTesting);
    return;
  }

  if (!protocol_) {
    ESP_LOGE(TAG, "Protocol not initialized");
    return;
  }

  if (device_state_ == kDeviceStateIdle) {
    Schedule([this]() {
      if (!protocol_->IsAudioChannelOpened()) {
        SetDeviceState(kDeviceStateConnecting);
        if (!protocol_->OpenAudioChannel()) {
          return;
        }
      }

      SetListeningMode(kListeningModeManualStop);
    });
  } else if (device_state_ == kDeviceStateSpeaking) {
    Schedule([this]() {
      AbortSpeaking(kAbortReasonNone);
      SetListeningMode(kListeningModeManualStop);
    });
  }
}

void Application::StopListening() {
  if (device_state_ == kDeviceStateAudioTesting) {
    audio_service_.EnableAudioTesting(false);
    SetDeviceState(kDeviceStateWifiConfiguring);
    return;
  }

  const std::array<int, 3> valid_states = {
      kDeviceStateListening,
      kDeviceStateSpeaking,
      kDeviceStateIdle,
  };
  // If not valid, do nothing
  if (std::find(valid_states.begin(), valid_states.end(), device_state_) ==
      valid_states.end()) {
    return;
  }

  Schedule([this]() {
    if (device_state_ == kDeviceStateListening) {
      protocol_->SendStopListening();
      SetDeviceState(kDeviceStateIdle);
    }
  });
}

void Application::Start() {
  auto &board = Board::GetInstance();
  SetDeviceState(kDeviceStateStarting);

  /* Setup the display */
  auto display = board.GetDisplay();

  // Print board name/version info
  display->SetChatMessage("system", SystemInfo::GetUserAgent().c_str());

  /* Setup the audio service */
  auto codec = board.GetAudioCodec();
  audio_service_.Initialize(codec);
  audio_service_.Start();

  AudioServiceCallbacks callbacks;
  callbacks.on_send_queue_available = [this]() {
    xEventGroupSetBits(event_group_, MAIN_EVENT_SEND_AUDIO);
  };
  callbacks.on_wake_word_detected = [this](const std::string &wake_word) {
    xEventGroupSetBits(event_group_, MAIN_EVENT_WAKE_WORD_DETECTED);
  };
  callbacks.on_vad_change = [this](bool speaking) {
    xEventGroupSetBits(event_group_, MAIN_EVENT_VAD_CHANGE);
  };
  audio_service_.SetCallbacks(callbacks);

  // ğŸ§  åˆå§‹åŒ–äº‹ä»¶æ€»çº¿å’Œå­¦ä¹ ç³»ç»Ÿï¼ˆNVSå­˜å‚¨ï¼‰
  ESP_LOGI(TAG, "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
  ESP_LOGI(TAG, "ğŸ§  åˆå§‹åŒ–æ™ºèƒ½å­¦ä¹ ç³»ç»Ÿ (NVSå­˜å‚¨):");

  auto &event_bus = xiaozhi::EventBus::GetInstance();
  if (event_bus.Initialize() == ESP_OK) {
    ESP_LOGI(TAG, "  âœ… äº‹ä»¶æ€»çº¿åˆå§‹åŒ–æˆåŠŸ");
  } else {
    ESP_LOGE(TAG, "  âŒ äº‹ä»¶æ€»çº¿åˆå§‹åŒ–å¤±è´¥");
  }

  // âš ï¸  å·²ç¦ç”¨å­¦ä¹ ç³»ç»Ÿä»¥èŠ‚çœCPUå’Œå†…å­˜èµ„æº
  // auto &user_profile = xiaozhi::UserProfile::GetInstance();
  // if (user_profile.Initialize()) {
  //   ESP_LOGI(TAG, "  âœ… ç”¨æˆ·ç”»åƒåŠ è½½æˆåŠŸ (7däº’åŠ¨: %uæ¬¡)",
  //            user_profile.GetInteractionCount7d());
  // } else {
  //   ESP_LOGW(TAG, "  âš ï¸  ç”¨æˆ·ç”»åƒåŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼");
  // }

  // auto &decision_engine = xiaozhi::DecisionEngine::GetInstance();
  // if (decision_engine.Initialize()) {
  //   ESP_LOGI(TAG, "  âœ… å†³ç­–å¼•æ“åˆå§‹åŒ–æˆåŠŸ");
  // } else {
  //   ESP_LOGE(TAG, "  âŒ å†³ç­–å¼•æ“åˆå§‹åŒ–å¤±è´¥");
  // }

  // // ğŸ¯ åˆå§‹åŒ–è‡ªé€‚åº”è¡Œä¸ºç³»ç»Ÿ
  // auto &adaptive = xiaozhi::AdaptiveBehavior::GetInstance();
  // if (adaptive.Initialize()) {
  //   ESP_LOGI(TAG, "  âœ… è‡ªé€‚åº”è¡Œä¸ºç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ");
  //   ESP_LOGI(TAG, "    ğŸ“Š ç”¨æˆ·é¢‘ç‡ç­‰çº§: %d (0=ä½é¢‘, 1=ä¸­é¢‘, 2=é«˜é¢‘)",
  //            adaptive.GetUserFrequencyLevel());
  //   ESP_LOGI(TAG, "    ğŸ¾ å® ç‰©è¡°å‡é€Ÿç‡: %.2fx", adaptive.GetPetDecayRate());
  // } else {
  //   ESP_LOGW(TAG, "  âš ï¸  è‡ªé€‚åº”è¡Œä¸ºç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼");
  // }

  // // ğŸ’ åˆå§‹åŒ–æƒ…ç»ªè®°å¿†ç³»ç»Ÿ
  // auto &emotional_memory = xiaozhi::EmotionalMemory::GetInstance();
  // if (emotional_memory.Initialize()) {
  //   ESP_LOGI(TAG, "  âœ… æƒ…ç»ªè®°å¿†ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ");
  //   ESP_LOGI(TAG, "    ğŸ’” å­¤ç‹¬æ„Ÿ: %d/100",
  //            emotional_memory.GetLonelinessLevel());
  //   ESP_LOGI(TAG, "    âš¡ å…´å¥‹åº¦: %d/100",
  //            emotional_memory.GetExcitementLevel());
  //   ESP_LOGI(TAG, "    â¤ï¸  ä¿¡ä»»åº¦: %d/100", emotional_memory.GetTrustLevel());
  // } else {
  //   ESP_LOGW(TAG, "  âš ï¸  æƒ…ç»ªè®°å¿†ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼");
  // }
  
  ESP_LOGI(TAG, "  âš ï¸  å­¦ä¹ ç³»ç»Ÿå·²ç¦ç”¨ä»¥èŠ‚çœèµ„æº");

  // ğŸ“¡ æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨ï¼ˆå·²ç¦ç”¨ï¼Œå­¦ä¹ ç³»ç»Ÿå·²å…³é—­ï¼‰
  // event_bus.Subscribe(xiaozhi::LOGIC_EVENT, xiaozhi::LOGIC_CONVERSATION_END,
  //                     [&user_profile](void *event_data) {
  //                       ESP_LOGI(TAG, "ğŸ§ Event received: CONVERSATION_END");
  //                       ESP_LOGI(TAG,
  //                                "  ğŸ“Š User stats: 7däº’åŠ¨=%uæ¬¡, æœ€çˆ±è¯é¢˜=%s",
  //                                user_profile.GetInteractionCount7d(),
  //                                user_profile.GetFavoriteTopic());
  //                     });
  // ESP_LOGI(TAG, "  âœ… æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨: CONVERSATION_END");

  ESP_LOGI(TAG, "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");

  // ğŸ¯ æ˜¾ç¤ºéŸ³é¢‘å¤„ç†é…ç½®æ‘˜è¦
  ESP_LOGI(TAG, "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
  ESP_LOGI(TAG, "ğŸ“Š éŸ³é¢‘å¤„ç†é…ç½®æ‘˜è¦:");
#ifdef CONFIG_SR_NSN_NSNET2
  ESP_LOGI(TAG, "  ğŸ§  é™å™ª: NSNet2 ç¥ç»ç½‘ç»œ");
#elif defined(CONFIG_SR_NSN_WEBRTC)
  ESP_LOGI(TAG, "  ğŸ”¹ é™å™ª: WebRTC ä¼ ç»Ÿç®—æ³•");
#else
  ESP_LOGI(TAG, "  âŒ é™å™ª: æœªå¯ç”¨");
#endif

#ifdef CONFIG_SR_VADN_VADNET1_MEDIUM
  ESP_LOGI(TAG, "  ğŸ§  VAD: VADNet1 ç¥ç»ç½‘ç»œ");
#elif defined(CONFIG_SR_VADN_WEBRTC)
  ESP_LOGI(TAG, "  ğŸ”¹ VAD: WebRTC ä¼ ç»Ÿç®—æ³•");
#else
  ESP_LOGI(TAG, "  âŒ VAD: æœªå¯ç”¨");
#endif

  ESP_LOGI(TAG, "  âœ… AGC: WEBRTC æ¨¡å¼ (15dB æ¿€è¿›å¢ç›Š)");
  ESP_LOGI(TAG, "  âœ… SE:  è¯­éŸ³å¢å¼º (çªå‡ºäººå£°é¢‘æ®µ)");
  ESP_LOGI(TAG, "  âœ… AEC: å›å£°æ¶ˆé™¤ (å–å†³äºç¡¬ä»¶)");
  ESP_LOGI(TAG, "  âš™ï¸  Ringbuffer: 300, ä¼˜å…ˆçº§: 4, æ ¸å¿ƒ: CPU1");
  ESP_LOGI(TAG, "  â„¹ï¸  æ³¨æ„: ç¥ç»ç½‘ç»œç®—æ³•åœ¨é¦–æ¬¡è¯´è¯æ—¶æ‰ä¼šåŠ è½½");
  ESP_LOGI(TAG, "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");

  // Start the main event loop task with priority 3
  xTaskCreate(
      [](void *arg) {
        ((Application *)arg)->MainEventLoop();
        vTaskDelete(NULL);
      },
      "main_event_loop", 2048 * 4, this, 3, &main_event_loop_task_handle_);

  /* Start the clock timer to update the status bar */
  esp_timer_start_periodic(clock_timer_handle_, 1000000);

  /* Wait for the network to be ready */
  board.StartNetwork();

  // Update the status bar immediately to show the network state
  display->UpdateStatusBar(true);

  // Check for new assets version
  CheckAssetsVersion();

  // Check for new firmware version or get the MQTT broker address
  Ota ota;
  CheckNewVersion(ota);

  // Initialize the protocol
  display->SetStatus(Lang::Strings::LOADING_PROTOCOL);

  // Add MCP common tools before initializing the protocol
  auto &mcp_server = McpServer::GetInstance();
  mcp_server.AddCommonTools();
  mcp_server.AddUserOnlyTools();

  // ğŸ¾ å·²ç¦ç”¨ç”µå­å® ç‰©ç³»ç»Ÿä»¥èŠ‚çœCPUå’Œå†…å­˜èµ„æº
  // auto &pet_system = PetSystem::GetInstance();
  // ESP_LOGI(TAG, "  â„¹ï¸  å® ç‰©ç³»ç»Ÿï¼šä»…æ”¯æŒæ‰‹åŠ¨æŸ¥è¯¢ï¼ˆè¯´'å® ç‰©çŠ¶æ€'ï¼‰");
  // pet_system.Start();
  ESP_LOGI(TAG, "  âš ï¸  å® ç‰©ç³»ç»Ÿå·²ç¦ç”¨ä»¥èŠ‚çœèµ„æº");

  if (ota.HasMqttConfig()) {
    protocol_ = std::make_unique<MqttProtocol>();
  } else if (ota.HasWebsocketConfig()) {
    protocol_ = std::make_unique<WebsocketProtocol>();
  } else {
    ESP_LOGW(TAG, "No protocol specified in the OTA config, using MQTT");
    protocol_ = std::make_unique<MqttProtocol>();
  }

  protocol_->OnConnected([this]() { DismissAlert(); });

  protocol_->OnNetworkError([this](const std::string &message) {
    last_error_message_ = message;
    xEventGroupSetBits(event_group_, MAIN_EVENT_ERROR);
  });
  protocol_->OnIncomingAudio([this](std::unique_ptr<AudioStreamPacket> packet) {
    if (device_state_ == kDeviceStateSpeaking) {
      audio_service_.PushPacketToDecodeQueue(std::move(packet));
    }
  });
  protocol_->OnAudioChannelOpened([this, codec, &board]() {
    board.SetPowerSaveMode(false);
    if (protocol_->server_sample_rate() != codec->output_sample_rate()) {
      ESP_LOGW(TAG,
               "Server sample rate %d does not match device output sample rate "
               "%d, resampling may cause distortion",
               protocol_->server_sample_rate(), codec->output_sample_rate());
    }
  });
  protocol_->OnAudioChannelClosed([this, &board]() {
    board.SetPowerSaveMode(true);
    Schedule([this]() {
      auto display = Board::GetInstance().GetDisplay();
      display->SetChatMessage("system", "");
      SetDeviceState(kDeviceStateIdle);

      if (touch_message_pending_) {
        ESP_LOGW(
            TAG,
            "Touch: audio channel closed before message completed (error)");
        touch_message_pending_ = false;
        touch_waiting_start_ack_ = false;
        touch_start_request_time_us_ = 0;
      }
      touch_channel_opened_for_touch_ = false;
    });
  });
  protocol_->OnIncomingJson([this, display](const cJSON *root) {
    // Parse JSON data
    auto type = cJSON_GetObjectItem(root, "type");
    if (strcmp(type->valuestring, "listen") == 0) {
      // Touch events no longer use listen ack mechanism
      // AI responds directly to MCP notifications
    } else if (strcmp(type->valuestring, "tts") == 0) {
      auto state = cJSON_GetObjectItem(root, "state");
      if (strcmp(state->valuestring, "start") == 0) {
        Schedule([this]() {
          aborted_ = false;
          if (device_state_ == kDeviceStateIdle ||
              device_state_ == kDeviceStateListening) {
            SetDeviceState(kDeviceStateSpeaking);
          }
        });
      } else if (strcmp(state->valuestring, "stop") == 0) {
        Schedule([this]() {
          if (device_state_ == kDeviceStateSpeaking) {
            // ğŸ›¡ï¸ ç­‰å¾…éŸ³é¢‘æ’­æ”¾å®Œæˆåå†åˆ‡æ¢çŠ¶æ€
            ESP_LOGI(TAG, "æ”¶åˆ° stop æ¶ˆæ¯ï¼Œç­‰å¾…éŸ³é¢‘æ’­æ”¾å®Œæˆ...");

            // ç­‰å¾…æ‰€æœ‰éŸ³é¢‘é˜Ÿåˆ—æ¸…ç©ºï¼ˆæœ€å¤šç­‰å¾…10ç§’ï¼‰
            int wait_count = 0;
            while (!audio_service_.IsIdle() && wait_count < 100) {
              vTaskDelay(pdMS_TO_TICKS(100)); // æ¯100msæ£€æŸ¥ä¸€æ¬¡
              wait_count++;
            }

            if (wait_count >= 100) {
              ESP_LOGW(TAG, "ç­‰å¾…éŸ³é¢‘æ’­æ”¾è¶…æ—¶ï¼ˆ10ç§’ï¼‰ï¼Œå¼ºåˆ¶åˆ‡æ¢çŠ¶æ€");
            } else {
              ESP_LOGI(TAG, "éŸ³é¢‘æ’­æ”¾å®Œæˆï¼Œç”¨æ—¶ %d ms", wait_count * 100);
            }

            // ğŸ§  è®°å½•å¯¹è¯ï¼ˆå·²ç¦ç”¨ï¼Œå­¦ä¹ ç³»ç»Ÿå·²å…³é—­ï¼‰
            // auto &profile = xiaozhi::UserProfile::GetInstance();
            // profile.RecordInteraction("chat", 5000); // å‡è®¾5ç§’å¯¹è¯
            // profile.CheckAutoSave();

            // ğŸ“¡ å‘å¸ƒå¯¹è¯ç»“æŸäº‹ä»¶ï¼ˆäº‹ä»¶æ€»çº¿ï¼‰
            auto &event_bus = xiaozhi::EventBus::GetInstance();
            event_bus.Publish(xiaozhi::LOGIC_EVENT,
                              xiaozhi::LOGIC_CONVERSATION_END, nullptr);
            ESP_LOGI(TAG, "ğŸ“¡ Event published: CONVERSATION_END");

            // Ensure microphone is unmuted for the next turn
            audio_service_.SetInputMute(false);

            if (listening_mode_ == kListeningModeManualStop) {
              SetDeviceState(kDeviceStateIdle);
            } else {
              SetDeviceState(kDeviceStateListening);
            }
          }
        });
      } else if (strcmp(state->valuestring, "sentence_start") == 0) {
        auto text = cJSON_GetObjectItem(root, "text");
        if (cJSON_IsString(text)) {
          ESP_LOGI(TAG, "<< %s", text->valuestring);
          Schedule([this, display, message = std::string(text->valuestring)]() {
            display->SetChatMessage("assistant", message.c_str());
          });
        }
      }
    } else if (strcmp(type->valuestring, "stt") == 0) {
      auto text = cJSON_GetObjectItem(root, "text");
      if (cJSON_IsString(text)) {
        ESP_LOGI(TAG, ">> %s", text->valuestring);
        Schedule([this, display, message = std::string(text->valuestring)]() {
          display->SetChatMessage("user", message.c_str());
          // ğŸ¾ è®°å½•èŠå¤©ï¼ˆå·²ç¦ç”¨ï¼Œå® ç‰©ç³»ç»Ÿå·²å…³é—­ï¼‰
          // PetSystem::GetInstance().RecordChat();
        });
      }
    } else if (strcmp(type->valuestring, "llm") == 0) {
      auto emotion = cJSON_GetObjectItem(root, "emotion");
      if (cJSON_IsString(emotion)) {
        Schedule(
            [this, display, emotion_str = std::string(emotion->valuestring)]() {
              display->SetEmotion(emotion_str.c_str());
            });
      }
    } else if (strcmp(type->valuestring, "mcp") == 0) {
      auto payload = cJSON_GetObjectItem(root, "payload");
      if (cJSON_IsObject(payload)) {
        McpServer::GetInstance().ParseMessage(payload);
      }
    } else if (strcmp(type->valuestring, "system") == 0) {
      auto command = cJSON_GetObjectItem(root, "command");
      if (cJSON_IsString(command)) {
        ESP_LOGI(TAG, "System command: %s", command->valuestring);
        if (strcmp(command->valuestring, "reboot") == 0) {
          // Do a reboot if user requests a OTA update
          Schedule([this]() { Reboot(); });
        } else {
          ESP_LOGW(TAG, "Unknown system command: %s", command->valuestring);
        }
      }
    } else if (strcmp(type->valuestring, "alert") == 0) {
      auto status = cJSON_GetObjectItem(root, "status");
      auto message = cJSON_GetObjectItem(root, "message");
      auto emotion = cJSON_GetObjectItem(root, "emotion");
      if (cJSON_IsString(status) && cJSON_IsString(message) &&
          cJSON_IsString(emotion)) {
        Alert(status->valuestring, message->valuestring, emotion->valuestring,
              Lang::Sounds::OGG_VIBRATION);
      } else {
        ESP_LOGW(TAG, "Alert command requires status, message and emotion");
      }
#if CONFIG_RECEIVE_CUSTOM_MESSAGE
    } else if (strcmp(type->valuestring, "custom") == 0) {
      auto payload = cJSON_GetObjectItem(root, "payload");
      ESP_LOGI(TAG, "Received custom message: %s",
               cJSON_PrintUnformatted(root));
      if (cJSON_IsObject(payload)) {
        Schedule(
            [this, display,
             payload_str = std::string(cJSON_PrintUnformatted(payload))]() {
              display->SetChatMessage("system", payload_str.c_str());
            });
      } else {
        ESP_LOGW(TAG, "Invalid custom message format: missing payload");
      }
#endif
    } else {
      ESP_LOGW(TAG, "Unknown message type: %s", type->valuestring);
    }
  });
  bool protocol_started = protocol_->Start();

  SystemInfo::PrintHeapStats();
  SetDeviceState(kDeviceStateIdle);

  has_server_time_ = ota.HasServerTime();
  if (protocol_started) {
    std::string message =
        std::string(Lang::Strings::VERSION) + ota.GetCurrentVersion();
    display->ShowNotification(message.c_str());
    display->SetChatMessage("system", "");
    // Play the success sound to indicate the device is ready
    audio_service_.PlaySound(Lang::Sounds::OGG_SUCCESS);
  }
}

// Add a async task to MainLoop
void Application::Schedule(std::function<void()> callback) {
  {
    std::lock_guard<std::mutex> lock(mutex_);
    main_tasks_.push_back(std::move(callback));
  }
  xEventGroupSetBits(event_group_, MAIN_EVENT_SCHEDULE);
}

// The Main Event Loop controls the chat state and websocket connection
// If other tasks need to access the websocket or chat state,
// they should use Schedule to call this function
void Application::MainEventLoop() {
  while (true) {
    auto bits = xEventGroupWaitBits(
        event_group_,
        MAIN_EVENT_SCHEDULE | MAIN_EVENT_SEND_AUDIO |
            MAIN_EVENT_WAKE_WORD_DETECTED | MAIN_EVENT_VAD_CHANGE |
            MAIN_EVENT_CLOCK_TICK | MAIN_EVENT_ERROR,
        pdTRUE, pdFALSE, portMAX_DELAY);

    if (bits & MAIN_EVENT_ERROR) {
      SetDeviceState(kDeviceStateIdle);
      Alert(Lang::Strings::ERROR, last_error_message_.c_str(), "circle_xmark",
            Lang::Sounds::OGG_EXCLAMATION);
    }

    if (bits & MAIN_EVENT_SEND_AUDIO) {
      while (auto packet = audio_service_.PopPacketFromSendQueue()) {
        if (protocol_ && !protocol_->SendAudio(std::move(packet))) {
          break;
        }
      }
    }

    if (bits & MAIN_EVENT_WAKE_WORD_DETECTED) {
      OnWakeWordDetected();
    }

    if (bits & MAIN_EVENT_VAD_CHANGE) {
      if (device_state_ == kDeviceStateListening) {
        auto led = Board::GetInstance().GetLed();
        led->OnStateChanged();
      }
    }

    if (bits & MAIN_EVENT_SCHEDULE) {
      std::unique_lock<std::mutex> lock(mutex_);
      auto tasks = std::move(main_tasks_);
      lock.unlock();
      for (auto &task : tasks) {
        task();
      }
    }

    if (bits & MAIN_EVENT_CLOCK_TICK) {
      clock_ticks_++;
      auto display = Board::GetInstance().GetDisplay();
      display->UpdateStatusBar();

      // Touch events no longer use ack/timeout mechanism

      // Print the debug info every 10 seconds
      if (clock_ticks_ % 10 == 0) {
        // SystemInfo::PrintTaskCpuUsage(pdMS_TO_TICKS(1000));
        // SystemInfo::PrintTaskList();
        SystemInfo::PrintHeapStats();
      }
    }
  }
}

void Application::OnWakeWordDetected() {
  if (!protocol_) {
    return;
  }

  if (device_state_ == kDeviceStateIdle) {
    audio_service_.EncodeWakeWord();

    if (!protocol_->IsAudioChannelOpened()) {
      SetDeviceState(kDeviceStateConnecting);
      if (!protocol_->OpenAudioChannel()) {
        audio_service_.EnableWakeWordDetection(true);
        return;
      }
    }

    auto wake_word = audio_service_.GetLastWakeWord();
    ESP_LOGI(TAG, "Wake word detected: %s", wake_word.c_str());
#if CONFIG_SEND_WAKE_WORD_DATA
    // Encode and send the wake word data to the server
    while (auto packet = audio_service_.PopWakeWordPacket()) {
      protocol_->SendAudio(std::move(packet));
    }
    // Set the chat state to wake word detected
    protocol_->SendWakeWordDetected(wake_word);
    SetListeningMode(aec_mode_ == kAecOff ? kListeningModeAutoStop
                                          : kListeningModeRealtime);
#else
    SetListeningMode(aec_mode_ == kAecOff ? kListeningModeAutoStop
                                          : kListeningModeRealtime);
    // Play the pop up sound to indicate the wake word is detected
    audio_service_.PlaySound(Lang::Sounds::OGG_POPUP);
#endif
  } else if (device_state_ == kDeviceStateSpeaking) {
    AbortSpeaking(kAbortReasonWakeWordDetected);
  } else if (device_state_ == kDeviceStateActivating) {
    SetDeviceState(kDeviceStateIdle);
  }
}

void Application::AbortSpeaking(AbortReason reason) {
  ESP_LOGI(TAG, "Abort speaking");
  aborted_ = true;
  if (protocol_) {
    protocol_->SendAbortSpeaking(reason);
  }
  // Ensure immediate silence by resetting the decoder
  audio_service_.ResetDecoder();
}

void Application::SetListeningMode(ListeningMode mode) {
  listening_mode_ = mode;
  SetDeviceState(kDeviceStateListening);
}

void Application::SetDeviceState(DeviceState state) {
  if (device_state_ == state) {
    return;
  }

  clock_ticks_ = 0;
  auto previous_state = device_state_;
  device_state_ = state;
  ESP_LOGI(TAG, "STATE: %s", STATE_STRINGS[device_state_]);

  // Send the state change event
  DeviceStateEventManager::GetInstance().PostStateChangeEvent(previous_state,
                                                              state);

  auto &board = Board::GetInstance();
  auto display = board.GetDisplay();
  auto led = board.GetLed();
  led->OnStateChanged();
  switch (state) {
  case kDeviceStateUnknown:
  case kDeviceStateIdle:
    display->SetStatus(Lang::Strings::STANDBY);
    display->SetEmotion("neutral");
    audio_service_.EnableVoiceProcessing(false);
    audio_service_.EnableWakeWordDetection(true);

    // ğŸ‘† å»¶è¿Ÿåˆå§‹åŒ–è§¦æ‘¸æ£€æµ‹ï¼ˆä½¿ç”¨å®šæ—¶å™¨ï¼Œé¿å…é˜»å¡ä¸»äº‹ä»¶å¾ªç¯ï¼‰
    if (!touch_initialized_) {
      touch_initialized_ = true;
      ESP_LOGI(TAG, "Will initialize touch handler (GPIO13) in 2 seconds...");

      // åˆ›å»ºä¸€æ¬¡æ€§å®šæ—¶å™¨æ¥å»¶è¿Ÿåˆå§‹åŒ–
      esp_timer_create_args_t timer_args = {
          .callback =
              [](void *arg) {
                Application *app = static_cast<Application *>(arg);
                ESP_LOGI(TAG, "Initializing touch handler on GPIO13...");
                esp_err_t ret = app->touch_handler_.Start([app]() {
                  app->Schedule([app]() { app->OnTouchDetected(); });
                });
                if (ret != ESP_OK) {
                  ESP_LOGW(TAG,
                           "Touch handler initialization failed (%s), "
                           "continuing without touch support",
                           esp_err_to_name(ret));
                }
              },
          .arg = this,
          .dispatch_method = ESP_TIMER_TASK,
          .name = "touch_init_timer"};

      esp_timer_handle_t touch_init_timer;
      if (esp_timer_create(&timer_args, &touch_init_timer) == ESP_OK) {
        // å»¶è¿Ÿ2ç§’ååˆå§‹åŒ–ï¼ˆç¡®ä¿éŸ³é¢‘ç³»ç»Ÿå®Œå…¨ç¨³å®šï¼‰
        esp_timer_start_once(touch_init_timer, 2000000); // 2ç§’ = 2,000,000 å¾®ç§’
      } else {
        ESP_LOGE(TAG, "Failed to create touch init timer");
      }
    }
    break;
  case kDeviceStateConnecting:
    display->SetStatus(Lang::Strings::CONNECTING);
    display->SetEmotion("neutral");
    display->SetChatMessage("system", "");
    break;
  case kDeviceStateListening:
    display->SetStatus(Lang::Strings::LISTENING);
    display->SetEmotion("neutral");

    // Send start listening if audio processor isn't running
    if (!audio_service_.IsAudioProcessorRunning()) {
      protocol_->SendStartListening(listening_mode_);
    }

    // Always enable voice processing when entering Listening state
    // This is critical for VAD to work after state transitions
    audio_service_.EnableVoiceProcessing(true);
    audio_service_.EnableWakeWordDetection(false);
    break;
  case kDeviceStateSpeaking:
    display->SetStatus(Lang::Strings::SPEAKING);

    //  âš ï¸  Barge-in æš‚æ—¶ç¦ç”¨ï¼šESP-SR AFE ä¸æ”¯æŒ AEC + VAD åŒæ—¶è¿è¡Œ
    // Speaking çŠ¶æ€ä¸‹å…³é—­éŸ³é¢‘å¤„ç†ï¼Œé¿å… CPU è¿‡è½½å’Œ Ringbuffer æº¢å‡º
    // ç”¨æˆ·ä»å¯åœ¨ Listening çŠ¶æ€æ—¶æ‰“æ–­ï¼ˆè¯´è¯æ—¶æœºå™¨äººä¼šåœæ­¢è¯´è¯å¹¶ç›‘å¬ï¼‰
    if (listening_mode_ != kListeningModeRealtime) {
      audio_service_.EnableVoiceProcessing(false);
      // Only AFE wake word can be detected in speaking mode
      audio_service_.EnableWakeWordDetection(audio_service_.IsAfeWakeWord());
    }
    audio_service_.ResetDecoder();
    break;
  default:
    // Do nothing
    break;
  }
}

void Application::Reboot() {
  ESP_LOGI(TAG, "Rebooting...");
  // Disconnect the audio channel
  if (protocol_ && protocol_->IsAudioChannelOpened()) {
    protocol_->CloseAudioChannel();
  }
  protocol_.reset();
  audio_service_.Stop();

  vTaskDelay(pdMS_TO_TICKS(1000));
  esp_restart();
}

bool Application::UpgradeFirmware(Ota &ota, const std::string &url) {
  auto &board = Board::GetInstance();
  auto display = board.GetDisplay();

  // Use provided URL or get from OTA object
  std::string upgrade_url = url.empty() ? ota.GetFirmwareUrl() : url;
  std::string version_info =
      url.empty() ? ota.GetFirmwareVersion() : "(Manual upgrade)";

  // Close audio channel if it's open
  if (protocol_ && protocol_->IsAudioChannelOpened()) {
    ESP_LOGI(TAG, "Closing audio channel before firmware upgrade");
    protocol_->CloseAudioChannel();
  }
  ESP_LOGI(TAG, "Starting firmware upgrade from URL: %s", upgrade_url.c_str());

  Alert(Lang::Strings::OTA_UPGRADE, Lang::Strings::UPGRADING, "download",
        Lang::Sounds::OGG_UPGRADE);
  vTaskDelay(pdMS_TO_TICKS(3000));

  SetDeviceState(kDeviceStateUpgrading);

  std::string message = std::string(Lang::Strings::NEW_VERSION) + version_info;
  display->SetChatMessage("system", message.c_str());

  board.SetPowerSaveMode(false);
  audio_service_.Stop();
  vTaskDelay(pdMS_TO_TICKS(1000));

  bool upgrade_success = ota.StartUpgradeFromUrl(
      upgrade_url, [display](int progress, size_t speed) {
        std::thread([display, progress, speed]() {
          char buffer[32];
          snprintf(buffer, sizeof(buffer), "%d%% %uKB/s", progress,
                   speed / 1024);
          display->SetChatMessage("system", buffer);
        }).detach();
      });

  if (!upgrade_success) {
    // Upgrade failed, restart audio service and continue running
    ESP_LOGE(TAG, "Firmware upgrade failed, restarting audio service and "
                  "continuing operation...");
    audio_service_.Start();       // Restart audio service
    board.SetPowerSaveMode(true); // Restore power save mode
    Alert(Lang::Strings::ERROR, Lang::Strings::UPGRADE_FAILED, "circle_xmark",
          Lang::Sounds::OGG_EXCLAMATION);
    vTaskDelay(pdMS_TO_TICKS(3000));
    return false;
  } else {
    // Upgrade success, reboot immediately
    ESP_LOGI(TAG, "Firmware upgrade successful, rebooting...");
    display->SetChatMessage("system", "Upgrade successful, rebooting...");
    vTaskDelay(pdMS_TO_TICKS(1000)); // Brief pause to show message
    Reboot();
    return true;
  }
}

void Application::WakeWordInvoke(const std::string &wake_word) {
  if (device_state_ == kDeviceStateIdle) {
    ToggleChatState();
    Schedule([this, wake_word]() {
      if (protocol_) {
        protocol_->SendWakeWordDetected(wake_word);
      }
    });
  } else if (device_state_ == kDeviceStateSpeaking) {
    Schedule([this]() { AbortSpeaking(kAbortReasonNone); });
  } else if (device_state_ == kDeviceStateListening) {
    Schedule([this]() {
      if (protocol_) {
        protocol_->CloseAudioChannel();
      }
    });
  }
}

bool Application::CanEnterSleepMode() {
  if (device_state_ != kDeviceStateIdle) {
    return false;
  }

  if (protocol_ && protocol_->IsAudioChannelOpened()) {
    return false;
  }

  if (!audio_service_.IsIdle()) {
    return false;
  }

  // Now it is safe to enter sleep mode
  return true;
}

void Application::SendMcpMessage(const std::string &payload) {
  if (protocol_ == nullptr) {
    return;
  }

  // Make sure you are using main thread to send MCP message
  if (xTaskGetCurrentTaskHandle() == main_event_loop_task_handle_) {
    protocol_->SendMcpMessage(payload);
  } else {
    Schedule([this, payload = std::move(payload)]() {
      protocol_->SendMcpMessage(payload);
    });
  }
}

void Application::SetAecMode(AecMode mode) {
  aec_mode_ = mode;
  Schedule([this]() {
    auto &board = Board::GetInstance();
    auto display = board.GetDisplay();
    switch (aec_mode_) {
    case kAecOff:
      audio_service_.EnableDeviceAec(false);
      display->ShowNotification(Lang::Strings::RTC_MODE_OFF);
      break;
    case kAecOnServerSide:
      audio_service_.EnableDeviceAec(false);
      display->ShowNotification(Lang::Strings::RTC_MODE_ON);
      break;
    case kAecOnDeviceSide:
      audio_service_.EnableDeviceAec(true);
      display->ShowNotification(Lang::Strings::RTC_MODE_ON);
      break;
    }

    // If the AEC mode is changed, close the audio channel
    if (protocol_ && protocol_->IsAudioChannelOpened()) {
      protocol_->CloseAudioChannel();
    }
  });
}

void Application::PlaySound(const std::string_view &sound) {
  audio_service_.PlaySound(sound);
}

void Application::OnTouchDetected() {
  ESP_LOGI(TAG, "Touch detected! Responding with happy emotion and sending "
                "message to AI");

  auto &board = Board::GetInstance();
  auto display = board.GetDisplay();

  display->SetEmotion("happy");

  if (!protocol_) {
    ESP_LOGW(TAG, "Cannot send touch message - protocol not initialized");
    return;
  }

  Schedule([this]() {
    if (touch_message_pending_) {
      ESP_LOGW(TAG, "Touch message already pending, ignoring additional touch");
      return;
    }

    touch_message_pending_ = true;

    auto start_touch_sequence = [this]() {
      ESP_LOGI(TAG, "Touch: starting touch interaction sequence");
      // éšæœºé€‰æ‹©æ‘‡æ‘†æˆ–è·³è·ƒåŠ¨ä½œ
      int random_action = esp_random() % 2;
      if (random_action == 0) {
        ESP_LOGI(TAG, "Touch: triggering Swing action");
        OttoSwing(2, 1000, 30);
      } else {
        ESP_LOGI(TAG, "Touch: triggering Jump action");
        OttoJump(1, 5000);  // æ…¢åŠ¨ä½œè·³è·ƒ
      }
      SendTouchStartSequence();
    };

    if (protocol_->IsAudioChannelOpened()) {
      if (device_state_ == kDeviceStateSpeaking) {
        ESP_LOGI(TAG, "Touch: aborting speech before starting touch sequence");
        AbortSpeaking(kAbortReasonNone);
      }
      start_touch_sequence();
      return;
    }

    if (device_state_ != kDeviceStateIdle) {
      ESP_LOGW(TAG, "Cannot start touch interaction - device busy");
      touch_message_pending_ = false;
      return;
    }

    ESP_LOGI(TAG, "Touch: audio channel closed, opening for touch interaction");
    SetDeviceState(kDeviceStateConnecting);
    touch_channel_opened_for_touch_ = true;

    if (!protocol_->OpenAudioChannel()) {
      ESP_LOGW(TAG, "Failed to open audio channel for touch interaction");
      touch_message_pending_ = false;
      touch_channel_opened_for_touch_ = false;
      SetDeviceState(kDeviceStateIdle);
      return;
    }

    ESP_LOGI(TAG, "Touch: audio channel opened, starting sequence");
    start_touch_sequence();

    if (device_state_ == kDeviceStateConnecting) {
      // The state will be updated to Listening when the channel is fully open
      // and we send the start command But for now, we can leave it as
      // Connecting or set to Idle if we want to be safe Actually,
      // OpenAudioChannel is async in terms of connection, but we called it
      // synchronously here? No, OpenAudioChannel returns bool immediately but
      // connection happens in background? Let's check OpenAudioChannel
      // implementation if needed. Based on existing code, it seems we just wait
      // for OnAudioChannelOpened or just proceed. In the original code: if
      // (device_state_ == kDeviceStateConnecting) {
      //    SetDeviceState(kDeviceStateIdle);
      // }
      // But here we want to stay in a state that allows interaction.
      // Let's keep it as Connecting, and it will transition to Listening when
      // SendStartListening is called in SendTouchStartSequence Wait,
      // SendTouchStartSequence calls protocol_->SendStartListening. If protocol
      // is not yet connected, SendStartListening might fail or be queued.
      // MqttProtocol::OpenAudioChannel usually initiates connection.
      // We might need to wait for OnAudioChannelOpened callback?
      // The original code had:
      // protocol_->OnAudioChannelOpened([this, codec, &board]() { ... });
      // This callback is already set in Start().

      // However, we are calling start_touch_sequence() immediately after
      // OpenAudioChannel(). If OpenAudioChannel() is not blocking until
      // connected, this might be too early. But the original code for MCP did
      // the same: if (!protocol_->OpenAudioChannel()) { ... } send_touch_mcp();

      // Let's assume it works similarly.
      // But wait, SendStartListening sends a JSON message. If the
      // websocket/mqtt is not connected, it will fail. If OpenAudioChannel just
      // starts the process, we might need to wait.

      // Actually, looking at ToggleChatState:
      // if (!protocol_->IsAudioChannelOpened()) {
      //     SetDeviceState(kDeviceStateConnecting);
      //     if (!protocol_->OpenAudioChannel()) { return; }
      // }
      // SetListeningMode(...);

      // So it seems we can call it immediately?
      // But SetListeningMode just sets the state. It doesn't send data
      // immediately? Wait, SetListeningMode calls protocol_->SendStartListening
      // if audio processor is not running.

      // Let's stick to the pattern.
    }
  });

  // æ’­æ”¾å¼€å¿ƒçš„éŸ³æ•ˆï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
  // audio_service_.PlaySound(Lang::Sounds::OGG_HAPPY);  //
  // å¦‚æœæœ‰å®šä¹‰å¼€å¿ƒéŸ³æ•ˆçš„è¯
}

void Application::SendTouchStartSequence() {
  if (!protocol_) {
    return;
  }

  ESP_LOGI(TAG, "Touch: starting sequence");

  // 1. If speaking, abort it
  if (device_state_ == kDeviceStateSpeaking) {
    AbortSpeaking(kAbortReasonNone);
  }

  // 2. Ensure audio channel is open (for subsequent audio streaming)
  if (!protocol_->IsAudioChannelOpened()) {
    SetDeviceState(kDeviceStateConnecting);
    if (!protocol_->OpenAudioChannel()) {
      ESP_LOGE(TAG, "Failed to open audio channel");
      return;
    }
  }

  // 3. Send Wake Word Detected (Text)
  // This triggers the server to respond
  ESP_LOGI(TAG, "Touch: sending wake word: %s", kTouchMessage);
  protocol_->SendWakeWordDetected(kTouchMessage);

  // 4. Set listening mode based on AEC capability
  // If AEC is off, we must use AutoStop to avoid recording the speaker output
  // (echo)
  if (aec_mode_ == kAecOff) {
    listening_mode_ = kListeningModeAutoStop;
  } else {
    listening_mode_ = kListeningModeRealtime;
  }
  SetDeviceState(kDeviceStateListening);

  // 5. Send MCP notification as backup/context
  SendTouchEventViaMcp();

  touch_message_pending_ = false;
  touch_waiting_start_ack_ = false;
  touch_start_request_time_us_ = 0;

  if (touch_channel_opened_for_touch_) {
    touch_channel_opened_for_touch_ = false;
  }
}

void Application::SendTouchEventViaMcp() {
  if (!protocol_) {
    return;
  }

  cJSON *meta = cJSON_CreateObject();
  cJSON_AddStringToObject(meta, "source", "touch_sensor");
  cJSON_AddStringToObject(meta, "emotion", "happy");

  cJSON *params = cJSON_CreateObject();
  cJSON_AddStringToObject(params, "event", "touch");
  cJSON_AddStringToObject(params, "message", kTouchMessage);
  cJSON_AddItemToObject(params, "meta", meta);

  cJSON *rpc = cJSON_CreateObject();
  cJSON_AddStringToObject(rpc, "jsonrpc", "2.0");
  cJSON_AddNumberToObject(rpc, "id", touch_mcp_request_id_++);
  cJSON_AddStringToObject(rpc, "method", "notifications/touch");
  cJSON_AddItemToObject(rpc, "params", params);

  char *payload_str = cJSON_PrintUnformatted(rpc);
  if (payload_str != nullptr) {
    ESP_LOGI(TAG, "Touch: MCP message: %s", payload_str);
    protocol_->SendMcpMessage(payload_str);
    cJSON_free(payload_str);
  }
  cJSON_Delete(rpc);
}
